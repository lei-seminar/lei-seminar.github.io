export const PAPER = "Paper"
export const REMARK = "Remarks"

export const SCALING_LAWS = [
    [
        "Training Compute-Optimal Large Language Models (“Chinchilla”)",
        "https://arxiv.org/abs/2203.15556",
        "This paper changed the way the field thinks about pretraining and data."
    ],
    [
        "Scaling laws for deep neural language networks",
        "https://arxiv.org/abs/2001.08361",
        "The original “Scaling Laws for LM work",
    ],
    [
        "Deep Learning Scaling is Predictable, Empirically",
        "https://arxiv.org/abs/1712.00409",
        ""
    ],
    [
        "Scaling laws literature review",
        "https://epochai.org/blog/scaling-laws-literature-review",
        ""
    ]
]
export const CHAIN_OF_THOUGHT_PROMPTING = [
    [
        "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
        "https://arxiv.org/abs/2201.11903",
        "Coined the term “chain of thought” and conducted detailed experiments"
    ],
    [
        "Show Your Work: Scratchpads for Intermediate Computation with Language Models",
        "https://arxiv.org/abs/2112.00114",
        "Earlier paper presenting the core idea behind chain of thought prompting"
    ],
    [
        "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm",
        "https://arxiv.org/abs/2102.07350",
        "Even earlier exploration of the same idea"
    ],
    [
        "Inner-Monologue",
        "https://gwern.net/doc/ai/nn/transformer/gpt/inner-monologue/index",
        "Chain of thought in a non-academic context"
    ]
]

export const RLHF = [
    [
        "Training Language Models to Follow Instructions with Human Feedback (“InstructGPT’)",
        "https://arxiv.org/abs/2203.02155",
        "Major impact via ChatGPT and popularized RLHF."
    ],
    [
        "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
        "https://arxiv.org/pdf/2204.05862.pdf",
        "Anthropic’s work on this topic"
    ],
    [
        "Learning to summarize from human feedback",
        "https://arxiv.org/abs/2009.01325",
        "Original precursor work to more recent RLHF"
    ]
]

export const EMERGING_ABILITIES = [
    [
        "Predictability and Surprise in Large Generative Models",
        "https://arxiv.org/abs/2202.07785",
        ""
    ],
    [
        "Emergent Abilities of Large Language Models",
        "https://arxiv.org/abs/2206.07682",
        "Survey paper"
    ]
]

export const TRANSFORMERS = [
    [
        "Attention is all You Need",
        "https://arxiv.org/abs/1706.03762",
        ""
    ],
    [
        "PaLM: Scaling Language Models with Pathways",
        "https://arxiv.org/abs/2204.02311",
        "Current SOTA LLM for academic benchmarks and enabler of many breakthroughs such as Flan-PaLM, PaLM-SayCan, Med-PaLM."
    ],
    [
        "Constitutional AI: Harmless from AI Feedback",
        "https://arxiv.org/abs/2212.08073",
        "Impactful idea that is already very impactful for LLM safety and also has applications beyond safety."
    ]
]

export const MIXTURE_OF_EXPERTS = [
    [
        "ST-MoE: Designing Stable and Transferable Sparse Expert Models",
        "https://arxiv.org/abs/2202.08906",
        "Best sparse model paper. Meticulous experiments, comprehensive evals and the goto reference for all sparse modeling."
    ],
    [
        "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
        "https://arxiv.org/pdf/1701.06538.pdf",
        ""
    ],
    [
        "Solving Quantitative Reasoning Problems with Language Models (“Minerva”)",
        "https://arxiv.org/abs/2206.14858",
        "Breakthrough results on Math."
    ],
    [
        "Scaling Instruction-Finetuned Language Models (“Flan2”)",
        "https://arxiv.org/abs/2210.11416",
        "Major Instruction Tuning work."
    ],
    [
        "Competition-level code Generation with AlphaCode",
        "https://arxiv.org/abs/2203.07814",
        "Breakthrough results on code."
    ],
    [
        "LaMDA: Language Model for Dialog Applications",
        "https://arxiv.org/abs/2201.08239",
        "Breakthrough on dialog especially on factuality and safety."
    ],
    [
        "Multitask Prompted Training Enables Zero-Shot Task Generalization (“T0”)",
        "https://arxiv.org/abs/2110.08207",
        "Great instruction tuning paper. While T0 is no longer SOTA, this was likely the best paper from BigScience."
    ],
    [
        "Language Models are Unsupervised Multitask Learners",
        "https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf",
        ""
    ]
]
