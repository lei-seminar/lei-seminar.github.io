<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="#000000" name="theme-color"><meta content="Web site created using create-react-app" name="description"><link href="/favicon.png" rel="shortcut icon"><link href="/manifest.json" rel="manifest"><title>LEI Seminar</title><script defer src="/static/js/main.c2a5efa7.js"></script><link href="/static/css/main.11a21736.css" rel="stylesheet"><style data-styled="active" data-styled-version="5.3.10">.jdpyoQ{background:#0f334a;height:50px;display:flex;padding-left:5em;margin-left:0;-webkit-box-pack:justify;justify-content:space-between}.cNAjdZ{display:flex;-webkit-box-align:center;align-items:center;text-decoration:none;padding:0 1rem;height:100%;cursor:pointer;font-size:20px;font-family:"Bree Serif",serif;color:#fff!important}.cNAjdZ.active{font-weight:700;color:#fff!important}.cNAjdZ:hover{background-color:#2a6082;font-weight:700;text-decoration:none;color:#fff!important}.Whawq{display:none;color:grey}@media screen and (max-width:768px){.Whawq{display:block;position:absolute;top:0;right:0;transform:translate(-100%,75%);font-size:1.8rem;cursor:pointer}}.hqWkvK{display:flex;-webkit-box-align:center;align-items:center;margin-right:-24px}@media screen and (max-width:768px){.hqWkvK{display:none}}</style><link href="https://fonts.googleapis.com" rel="preconnect"><link href="https://fonts.gstatic.com" rel="preconnect"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id="root"><nav class="sc-bgqQcB jdpyoQ"><svg class="sc-ewnqHT Whawq" fill="currentColor" height="1em" stroke="currentColor" stroke-width="0" viewBox="0 0 448 512" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg><div class="sc-fFGjHI hqWkvK"><h3 style="padding-top:.3em;padding-right:1em;color:#fff">Large Language Models: Reading Group</h3><a href="/presentation" class="sc-gTRrQi cNAjdZ">Presentations</a><a href="/readinglist" class="sc-gTRrQi cNAjdZ active" aria-current="page">Reading List</a></div></nav><div class="[object Object]" style="padding:2em;justify-content:center"><div class="card-body"><h3>Scaling Laws</h3><table><tr><th>Paper</th><th>Remarks</th></tr><tr><td><a href="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models (“Chinchilla”)</a></td><td>This paper changed the way the field thinks about pretraining and data.</td></tr><tr><td><a href="https://arxiv.org/abs/2001.08361">Scaling laws for deep neural language networks</a></td><td>The original “Scaling Laws for LM work</td></tr><tr><td><a href="https://arxiv.org/abs/1712.00409">Deep Learning Scaling is Predictable, Empirically</a></td><td></td></tr><tr><td><a href="https://epochai.org/blog/scaling-laws-literature-review">Scaling laws literature review</a></td><td></td></tr></table></div><div class="card-body"><h3>Chain of Thought Prompting</h3><table><tr><th>Paper</th><th>Remarks</th></tr><tr><td><a href="https://arxiv.org/abs/2201.11903">Chain of Thought Prompting Elicits Reasoning in Large Language Models</a></td><td>Coined the term “chain of thought” and conducted detailed experiments</td></tr><tr><td><a href="https://arxiv.org/abs/2112.00114">Show Your Work: Scratchpads for Intermediate Computation with Language Models</a></td><td>Earlier paper presenting the core idea behind chain of thought prompting</td></tr><tr><td><a href="https://arxiv.org/abs/2102.07350">Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm</a></td><td>Even earlier exploration of the same idea</td></tr><tr><td><a href="https://gwern.net/doc/ai/nn/transformer/gpt/inner-monologue/index">Inner-Monologue</a></td><td>Chain of thought in a non-academic context</td></tr></table></div><div class="card-body"><h3>Reinforcement Learning with Human Feedback</h3><table><tr><th>Paper</th><th>Remarks</th></tr><tr><td><a href="https://arxiv.org/abs/2203.02155">Training Language Models to Follow Instructions with Human Feedback (“InstructGPT’)</a></td><td>Major impact via ChatGPT and popularized RLHF.</td></tr><tr><td><a href="https://arxiv.org/pdf/2204.05862.pdf">Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback</a></td><td>Anthropic’s work on this topic</td></tr><tr><td><a href="https://arxiv.org/abs/2009.01325">Learning to summarize from human feedback</a></td><td>Original precursor work to more recent RLHF</td></tr></table></div><div class="card-body"><h3>Emerging Abilities</h3><table><tr><th>Paper</th><th>Remarks</th></tr><tr><td><a href="https://arxiv.org/abs/2202.07785">Predictability and Surprise in Large Generative Models</a></td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2206.07682">Emergent Abilities of Large Language Models</a></td><td>Survey paper</td></tr></table></div><div class="card-body"><h3>Transformers</h3><table><tr><th>Paper</th><th>Remarks</th></tr><tr><td><a href="https://arxiv.org/abs/1706.03762">Attention is all You Need</a></td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2204.02311">PaLM: Scaling Language Models with Pathways</a></td><td>Current SOTA LLM for academic benchmarks and enabler of many breakthroughs such as Flan-PaLM, PaLM-SayCan, Med-PaLM.</td></tr><tr><td><a href="https://arxiv.org/abs/2212.08073">Constitutional AI: Harmless from AI Feedback</a></td><td>Impactful idea that is already very impactful for LLM safety and also has applications beyond safety.</td></tr></table></div><div class="card-body"><h3>Mixture of Experts</h3><table><tr><th>Paper</th><th>Remarks</th></tr><tr><td><a href="https://arxiv.org/abs/2202.08906">ST-MoE: Designing Stable and Transferable Sparse Expert Models</a></td><td>Best sparse model paper. Meticulous experiments, comprehensive evals and the goto reference for all sparse modeling.</td></tr><tr><td><a href="https://arxiv.org/pdf/1701.06538.pdf">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2206.14858">Solving Quantitative Reasoning Problems with Language Models (“Minerva”)</a></td><td>Breakthrough results on Math.</td></tr><tr><td><a href="https://arxiv.org/abs/2210.11416">Scaling Instruction-Finetuned Language Models (“Flan2”)</a></td><td>Major Instruction Tuning work.</td></tr><tr><td><a href="https://arxiv.org/abs/2203.07814">Competition-level code Generation with AlphaCode</a></td><td>Breakthrough results on code.</td></tr><tr><td><a href="https://arxiv.org/abs/2201.08239">LaMDA: Language Model for Dialog Applications</a></td><td>Breakthrough on dialog especially on factuality and safety.</td></tr><tr><td><a href="https://arxiv.org/abs/2110.08207">Multitask Prompted Training Enables Zero-Shot Task Generalization (“T0”)</a></td><td>Great instruction tuning paper. While T0 is no longer SOTA, this was likely the best paper from BigScience.</td></tr><tr><td><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a></td><td></td></tr></table></div></div></div></body></html>